{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:16:23.905573Z",
     "iopub.status.busy": "2022-07-03T08:16:23.905102Z",
     "iopub.status.idle": "2022-07-03T08:16:26.458226Z",
     "shell.execute_reply": "2022-07-03T08:16:26.457020Z",
     "shell.execute_reply.started": "2022-07-03T08:16:23.905476Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as AF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torchaudio.set_audio_backend(\"sox_io\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:13.725959Z",
     "iopub.status.busy": "2022-07-03T08:17:13.725107Z",
     "iopub.status.idle": "2022-07-03T08:17:13.743487Z",
     "shell.execute_reply": "2022-07-03T08:17:13.742571Z",
     "shell.execute_reply.started": "2022-07-03T08:17:13.725924Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum((y_true * y_pred) > 0.5) / torch.sum(y_true)\n",
    "\n",
    "def stem(file):\n",
    "    return file.split(\"/\")[-1]\n",
    "\n",
    "def find_files(directory, pattern='**/*.wav'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    return glob(os.path.join(directory, pattern), recursive=True)\n",
    "\n",
    "def seed_everywhere():\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self, name:str, momentum=0.95):\n",
    "        assert 0.0 <= momentum < 1.0\n",
    "        \n",
    "        self.name = name\n",
    "        self.momentum = momentum\n",
    "        self.x = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(\"{} -> {:0.3f}\".format(self.name, self.x))\n",
    "    \n",
    "    def get(self):\n",
    "        return self.x\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x = None\n",
    "        \n",
    "    def step(self, x: float):\n",
    "        if self.x is None:\n",
    "            self.x = x\n",
    "        else:\n",
    "            self.x = self.momentum * self.x + (1 - self.momentum) * x\n",
    "            \n",
    "class Timer(object):\n",
    "    def __init__(self):\n",
    "        self._tic = time.time()\n",
    "\n",
    "    def tic(self):\n",
    "        self._tic = time.time()\n",
    "        return self._tic\n",
    "\n",
    "    def toc(self):\n",
    "        return time.time() - self._tic\n",
    "\n",
    "    def tictoc(self):\n",
    "        _toc = time.time()\n",
    "        duration = _toc - self._tic\n",
    "        self._tic = _toc\n",
    "        return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:15.848479Z",
     "iopub.status.busy": "2022-07-03T08:17:15.848101Z",
     "iopub.status.idle": "2022-07-03T08:17:15.855342Z",
     "shell.execute_reply": "2022-07-03T08:17:15.853523Z",
     "shell.execute_reply.started": "2022-07-03T08:17:15.848440Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sound:\n",
    "    def __init__(self, \n",
    "                 path, \n",
    "                 sound_id=None,\n",
    "                 meta=None, \n",
    "                 samplerate=None):\n",
    "        self.path = str(path)\n",
    "        self.sound_id = sound_id\n",
    "        self.samplerate = samplerate\n",
    "        self.meta = meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Model and Loss\n",
    "link: https://arxiv.org/abs/2005.07143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:27.071139Z",
     "iopub.status.busy": "2022-07-03T08:17:27.070737Z",
     "iopub.status.idle": "2022-07-03T08:17:27.116023Z",
     "shell.execute_reply": "2022-07-03T08:17:27.114857Z",
     "shell.execute_reply.started": "2022-07-03T08:17:27.071106Z"
    }
   },
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, bottleneck=128):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Conv1d(channels, bottleneck, kernel_size=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(bottleneck),\n",
    "            nn.Conv1d(bottleneck, channels, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.se(input)\n",
    "        return input * x\n",
    "\n",
    "class Bottle2neck(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, kernel_size=None, dilation=None, scale = 4):\n",
    "\n",
    "        super(Bottle2neck, self).__init__()\n",
    "\n",
    "        width       = int(math.floor(planes / scale))\n",
    "        \n",
    "        self.conv1  = nn.Conv1d(inplanes, width*scale, kernel_size=1)\n",
    "        self.bn1    = nn.BatchNorm1d(width*scale)\n",
    "        \n",
    "        self.nums   = scale -1\n",
    "\n",
    "        convs       = []\n",
    "        bns         = []\n",
    "\n",
    "        num_pad = math.floor(kernel_size/2)*dilation\n",
    "\n",
    "        for i in range(self.nums):\n",
    "            convs.append(nn.Conv1d(width, width, kernel_size=kernel_size, dilation=dilation, padding=num_pad))\n",
    "            bns.append(nn.BatchNorm1d(width))\n",
    "\n",
    "        self.convs  = nn.ModuleList(convs)\n",
    "        self.bns    = nn.ModuleList(bns)\n",
    "\n",
    "        self.conv3  = nn.Conv1d(width*scale, planes, kernel_size=1)\n",
    "        self.bn3    = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.relu   = nn.ReLU()\n",
    "\n",
    "        self.width  = width\n",
    "        self.se     = SEModule(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        spx = torch.split(out, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i==0:\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.relu(sp)\n",
    "            sp = self.bns[i](sp)\n",
    "            if i==0:\n",
    "                out = sp\n",
    "            else:\n",
    "                out = torch.cat((out, sp), 1)\n",
    "                \n",
    "        out = torch.cat((out, spx[self.nums]),1)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.se(out)\n",
    "        out += residual\n",
    "\n",
    "        return out \n",
    "\n",
    "class ECAPA(nn.Module):\n",
    "    def __init__(self, \n",
    "                 C, \n",
    "                 model_scale, \n",
    "                 dim_out,\n",
    "                 features_dim, \n",
    "                 encoder_type=\"ASP\",\n",
    "                 context=False, \n",
    "                 summed=False, \n",
    "                 out_bn=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.context = context\n",
    "        self.summed = summed\n",
    "        self.features_dim = features_dim\n",
    "        self.encoder_type = encoder_type\n",
    "        self.out_bn = out_bn\n",
    "\n",
    "        self.scale  = model_scale\n",
    "\n",
    "        self.conv1  = nn.Conv1d(self.features_dim, C, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu   = nn.ReLU()\n",
    "        self.bn1    = nn.BatchNorm1d(C)\n",
    "        \n",
    "        self.layer1 = Bottle2neck(C, C, kernel_size=3, dilation=2, scale=self.scale)\n",
    "        self.layer2 = Bottle2neck(C, C, kernel_size=3, dilation=3, scale=self.scale)\n",
    "        self.layer3 = Bottle2neck(C, C, kernel_size=3, dilation=4, scale=self.scale)\n",
    "        self.layer4 = nn.Conv1d(3*C, 1536, kernel_size=1)\n",
    "\n",
    "        if self.context:\n",
    "            attn_input = 1536*3\n",
    "        else:\n",
    "            attn_input = 1536\n",
    "\n",
    "        if self.encoder_type == 'ECA':\n",
    "            attn_output = 1536\n",
    "        elif self.encoder_type == 'ASP':\n",
    "            attn_output = 1\n",
    "        else:\n",
    "            raise ValueError('Undefined encoder')\n",
    "\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(attn_input, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, attn_output, kernel_size=1),\n",
    "            nn.Softmax(dim=2),\n",
    "            )\n",
    "\n",
    "        self.bn5 = nn.BatchNorm1d(3072)\n",
    "\n",
    "        self.fc6 = nn.Linear(3072, dim_out)\n",
    "        if self.out_bn:\n",
    "            self.bn6 = nn.BatchNorm1d(dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        if self.summed:\n",
    "            x1 = self.layer1(x)\n",
    "            x2 = self.layer2(x+x1)\n",
    "            x3 = self.layer3(x+x1+x2)\n",
    "        else:\n",
    "            x1 = self.layer1(x)\n",
    "            x2 = self.layer2(x1)\n",
    "            x3 = self.layer3(x2)\n",
    "\n",
    "        x = self.layer4(torch.cat((x1,x2,x3),dim=1))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        t = x.size()[-1]\n",
    "\n",
    "        if self.context:\n",
    "            global_x = torch.cat((x,torch.mean(x,dim=2,keepdim=True).repeat(1,1,t), torch.sqrt(torch.var(x,dim=2,keepdim=True).clamp(min=1e-4)).repeat(1,1,t)), dim=1)\n",
    "        else:\n",
    "            global_x = x\n",
    "\n",
    "        w = self.attention(global_x)\n",
    "        mu = torch.sum(x * w, dim=2)\n",
    "        sg = torch.sqrt( ( torch.sum((x**2) * w, dim=2) - mu**2 ).clamp(min=1e-4) )\n",
    "        x = torch.cat((mu, sg), 1)\n",
    "\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "        if self.out_bn:\n",
    "            x = self.bn6(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def ECAPA_1KCSBN(model_scale=8, C=128, **kwargs):\n",
    "    model = ECAPA(C=C, \n",
    "                  model_scale = model_scale, \n",
    "                  context=True, \n",
    "                  summed=True, \n",
    "                  out_bn=True, \n",
    "                  **kwargs)\n",
    "    return model\n",
    "\n",
    "class BCE(nn.Module):\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, dim), requires_grad=True)\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        nn.init.xavier_normal_(self.weight, gain=1)\n",
    "        \n",
    "    def logit(self, x):\n",
    "        return F.linear(x, self.weight)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x.astype(\"float32\")).cuda()\n",
    "        with torch.no_grad():\n",
    "            logit = self.logit(x)\n",
    "            \n",
    "        return self.sigmoid(logit)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        logit = self.logit(x)\n",
    "        return self.bce(logit, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:28.812356Z",
     "iopub.status.busy": "2022-07-03T08:17:28.811928Z",
     "iopub.status.idle": "2022-07-03T08:17:28.824971Z",
     "shell.execute_reply": "2022-07-03T08:17:28.823800Z",
     "shell.execute_reply.started": "2022-07-03T08:17:28.812321Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioReader:\n",
    "    def __init__(self, \n",
    "                 samplerate:int, \n",
    "                 length:int = None):\n",
    "        self.samplerate = samplerate\n",
    "        self.length = length\n",
    "        print(\"initialize AudioReader with samplerate: {}\".format(self.samplerate))\n",
    "        \n",
    "    def load_audio(self, file:str, frame_offset:int=None, num_frames:int=None):\n",
    "        audio, sr = torchaudio.load(file,\n",
    "                                    channels_first=True,\n",
    "                                    frame_offset=frame_offset,\n",
    "                                    num_frames=num_frames)\n",
    "        if sr != self.samplerate:\n",
    "            audio = F.resample(audio, sr,  self.samplerate)\n",
    "        if audio.shape[0] > 0:\n",
    "            audio = torch.mean(audio, dim=0, keepdims=True)\n",
    "        return audio\n",
    "\n",
    "    def __call__(self, file, length=None):\n",
    "        if length is None:\n",
    "            length = self.length\n",
    "        elif length == -1:\n",
    "            length = None\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if length is None:\n",
    "            audio = self.load_audio(file)\n",
    "            return audio\n",
    "        \n",
    "        info = torchaudio.info(file)\n",
    "        audio_length = info.num_frames\n",
    "\n",
    "        frame_offset_max = max(audio_length - length, 0)\n",
    "        if frame_offset_max > 0:\n",
    "            frame_offset = random.randint(0, frame_offset_max)\n",
    "        else:\n",
    "            frame_offset = 0\n",
    "\n",
    "        num_frames = min(audio_length, length)\n",
    "        audio = self.load_audio(file,\n",
    "                                frame_offset=frame_offset,\n",
    "                                num_frames=num_frames)\n",
    "\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Padder\n",
    "It's useful for training to augment audio wave witch too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:31.640630Z",
     "iopub.status.busy": "2022-07-03T08:17:31.639708Z",
     "iopub.status.idle": "2022-07-03T08:17:31.655972Z",
     "shell.execute_reply": "2022-07-03T08:17:31.654889Z",
     "shell.execute_reply.started": "2022-07-03T08:17:31.640589Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioPadder:\n",
    "    def __init__(self, mode, value=0.0, random=False, length=None):\n",
    "        \"\"\"\n",
    "        :param mode: mode of padding, pass to torch.pad.\n",
    "        :param value: value, works only for constant_padding mode\n",
    "        :param random: if true - left and right offset will be random, otherwise only right side pad\n",
    "        :param length: length of final audio in samples\n",
    "        \"\"\"\n",
    "        assert mode in ['constant', 'circular']\n",
    "        self.mode = mode\n",
    "        self.value = value\n",
    "        self.random = random\n",
    "        self.length = length\n",
    "\n",
    "    def circular_pad(self, x: torch.Tensor, pad: tuple):\n",
    "        is_squeeze = False\n",
    "        if len(x.shape) == 2:\n",
    "            x = x[None, ...]\n",
    "            is_squeeze = True\n",
    "        elif len(x.shape) == 3:\n",
    "            pass\n",
    "        else:\n",
    "            raise \"only 2D and 3D tensors supported\"\n",
    "\n",
    "        x_len = x.shape[-1]\n",
    "        pad_len_left = pad[0]\n",
    "        pad_len_right = pad[1]\n",
    "\n",
    "        n_repeat_left = pad_len_left // x_len\n",
    "        n_offset_left = pad_len_left % x_len\n",
    "        n_repeat_right = pad_len_right // x_len\n",
    "        n_offset_right = pad_len_right % x_len\n",
    "        n_repeat = n_repeat_left + n_repeat_right + 1\n",
    "        if n_repeat > 1:\n",
    "            x = torch.cat([x] * n_repeat, dim=-1)\n",
    "        x = F.pad(x, (n_offset_left, n_offset_right), mode=\"circular\")\n",
    "        if is_squeeze:\n",
    "            x = x.squeeze(0)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x, length=None):\n",
    "        if length is None:\n",
    "            length = self.length\n",
    "\n",
    "        if len(x.shape) < 2:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        length_x = x.shape[1]\n",
    "        if length_x >= length:\n",
    "            return x\n",
    "\n",
    "        if self.random:\n",
    "            pad_left = max(0, length - length_x)\n",
    "            pad_left = torch.randint(0, pad_left, (1,))\n",
    "        else:\n",
    "            pad_left = 0\n",
    "        pad_right = max(0, length - length_x - pad_left)\n",
    "        if self.mode == \"circular\":\n",
    "            x = self.circular_pad(x, pad=(pad_left, pad_right))\n",
    "        else:\n",
    "            x = F.pad(x, (pad_left, pad_right, 0, 0), mode=self.mode)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Extractor\n",
    "Extract audio from file\n",
    "use combination reader and padder to create extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:45.272206Z",
     "iopub.status.busy": "2022-07-03T08:17:45.271767Z",
     "iopub.status.idle": "2022-07-03T08:17:45.284445Z",
     "shell.execute_reply": "2022-07-03T08:17:45.283128Z",
     "shell.execute_reply.started": "2022-07-03T08:17:45.272172Z"
    }
   },
   "outputs": [],
   "source": [
    "class RawExtractor:\n",
    "    def __init__(self,\n",
    "                 length,\n",
    "                 dithering: float=None,\n",
    "                 samplerate: int=16000,\n",
    "                 normed: bool =False\n",
    "                 ):\n",
    "        self.dithering = dithering\n",
    "        self.length = length\n",
    "        self.samplerate = samplerate\n",
    "        self.normed = normed       \n",
    "        self.audio_loader = AudioReader(samplerate=self.samplerate,\n",
    "                                        length=length)\n",
    "        \n",
    "        if length is not None:\n",
    "            self.audio_padder = AudioPadder(mode=\"constant\",\n",
    "                                            length=length,\n",
    "                                            random=True\n",
    "                                            )\n",
    "        else:\n",
    "            self.audio_padder = None\n",
    "\n",
    "    def make_dithering(self, audio):\n",
    "        return audio + self.dithering * torch.rand_like(audio)\n",
    "    \n",
    "    def normalize(self, audio):\n",
    "        audio = audio - torch.mean(audio)\n",
    "        audio = audio / (torch.std(audio) + 1e-6)\n",
    "        return audio\n",
    "        \n",
    "    def __call__(self, sound):\n",
    "        if not isinstance(sound, str):\n",
    "            sound = sound.path\n",
    "            \n",
    "        audio = self.audio_loader(file=sound, length=self.length)\n",
    "            \n",
    "        if self.normed:\n",
    "            audio = self.normalize(audio)\n",
    "            \n",
    "        if self.audio_padder is not None:\n",
    "            audio = self.audio_padder(x=audio, length=self.length)\n",
    "            \n",
    "        if self.dithering is not None:\n",
    "            audio = self.make_dithering(audio)\n",
    "            \n",
    "        return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:47.585064Z",
     "iopub.status.busy": "2022-07-03T08:17:47.584672Z",
     "iopub.status.idle": "2022-07-03T08:17:47.600880Z",
     "shell.execute_reply": "2022-07-03T08:17:47.599517Z",
     "shell.execute_reply.started": "2022-07-03T08:17:47.585021Z"
    }
   },
   "outputs": [],
   "source": [
    "class MFCC(nn.Module):\n",
    "    def __init__(self,\n",
    "                 win_length: int,\n",
    "                 hop_length: int,\n",
    "                 n_fft: int, \n",
    "                 n_mels: int, \n",
    "                 n_mfcc: int,\n",
    "                 f_min: float, \n",
    "                 f_max: float, \n",
    "                 sample_rate: int,\n",
    "                 log_mels=False,\n",
    "                 instancenorm=False\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.n_mels = n_mels\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window_fn = torch.hamming_window\n",
    "        self.log_mels = log_mels\n",
    "        \n",
    "        mfcc = torchaudio.transforms.MFCC\n",
    "        self.extractor = mfcc(sample_rate=self.sample_rate, \n",
    "                              n_mfcc = self.n_mfcc, \n",
    "                              log_mels=self.log_mels, \n",
    "                              dct_type = 2, \n",
    "                              melkwargs={'n_mels': self.n_mels, \n",
    "                                         'n_fft':self.n_fft, \n",
    "                                         'win_length':self.win_length, \n",
    "                                         'hop_length':self.hop_length, \n",
    "                                         'f_min':self.f_min, \n",
    "                                         'f_max':self.f_max, \n",
    "                                         'window_fn':self.window_fn})\n",
    "        \n",
    "        if instancenorm:\n",
    "            self.instancenorm   = nn.InstanceNorm1d(self.n_mels)\n",
    "        else:\n",
    "            self.instancenorm = None\n",
    "        \n",
    "    def dim(self):\n",
    "        return self.n_mfcc\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            if x.dim() == 3:\n",
    "                x = x.squeeze(1)\n",
    "\n",
    "            f = self.extractor(x)\n",
    "            if self.instancenorm is not None:\n",
    "                f = self.instancenorm(f)\n",
    "\n",
    "            return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:55.352373Z",
     "iopub.status.busy": "2022-07-03T08:17:55.351922Z",
     "iopub.status.idle": "2022-07-03T08:17:55.366542Z",
     "shell.execute_reply": "2022-07-03T08:17:55.365640Z",
     "shell.execute_reply.started": "2022-07-03T08:17:55.352336Z"
    }
   },
   "outputs": [],
   "source": [
    "class Fbank(nn.Module):\n",
    "    def __init__(self, \n",
    "                 win_length: int,\n",
    "                 hop_length: int,\n",
    "                 n_fft: int, \n",
    "                 f_min: float, \n",
    "                 f_max: float, \n",
    "                 n_mels: int, \n",
    "                 sample_rate: int,\n",
    "                 log_input=False,\n",
    "                 instancenorm=False,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.n_mels = n_mels\n",
    "        self.sample_rate = sample_rate\n",
    "        self.log_input = log_input\n",
    "        self.window_fn = torch.hamming_window\n",
    "        \n",
    "        self.extractor = T.MelSpectrogram(n_fft=self.n_fft,\n",
    "                                          win_length = self.win_length,\n",
    "                                          hop_length = self.hop_length,\n",
    "                                          f_min = self.f_min,\n",
    "                                          f_max = self.f_max,\n",
    "                                          n_mels = self.n_mels,\n",
    "                                          sample_rate = self.sample_rate,\n",
    "                                          window_fn = self.window_fn,\n",
    "                                          **kwargs)\n",
    "        if instancenorm:\n",
    "            self.instancenorm   = nn.InstanceNorm1d(self.n_mels)\n",
    "        else:\n",
    "            self.instancenorm = None\n",
    "\n",
    "    def dim(self):\n",
    "        return self.n_mels\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            if x.dim() == 3:\n",
    "                x = x.squeeze(1)\n",
    "\n",
    "            f = self.extractor(x)\n",
    "            if self.log_input:\n",
    "                f = (f + 1e-7).log()\n",
    "\n",
    "            if self.instancenorm is not None:\n",
    "                f = self.instancenorm(f)\n",
    "\n",
    "            return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain Augmentations\n",
    "simgple noise mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:17:58.915333Z",
     "iopub.status.busy": "2022-07-03T08:17:58.914090Z",
     "iopub.status.idle": "2022-07-03T08:17:58.927178Z",
     "shell.execute_reply": "2022-07-03T08:17:58.926265Z",
     "shell.execute_reply.started": "2022-07-03T08:17:58.915249Z"
    }
   },
   "outputs": [],
   "source": [
    "class NoiseAugment(nn.Module):\n",
    "    def __init__(self, snr_db_min: float, snr_db_max: float, dim=-1):\n",
    "        super().__init__()\n",
    "        assert snr_db_min < snr_db_max\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.snr_db_min = snr_db_min\n",
    "        self.snr_db_max = snr_db_max\n",
    "        self.snr_gap = snr_db_max - snr_db_min\n",
    "        \n",
    "    @staticmethod\n",
    "    def db_2_mag(db):\n",
    "        return 20 ** (db / 20)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            snr_db = self.snr_db_min + torch.rand(x.shape[0]) * self.snr_gap\n",
    "            snr_linear = self.db_2_mag(snr_db).to(x.dtype).to(x.device)\n",
    "\n",
    "            std_x = torch.std(x, dim=self.dim, keepdims=True)\n",
    "            scale = std_x.squeeze() / snr_linear\n",
    "            scale = scale.unsqueeze(1).unsqueeze(1)\n",
    "            return x + scale * torch.rand_like(x).to(x.dtype).to(x.device)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Domain Augmentations\n",
    "> [SpecAugment](https://arxiv.org/abs/1904.08779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:18:00.961806Z",
     "iopub.status.busy": "2022-07-03T08:18:00.961108Z",
     "iopub.status.idle": "2022-07-03T08:18:00.973351Z",
     "shell.execute_reply": "2022-07-03T08:18:00.971953Z",
     "shell.execute_reply.started": "2022-07-03T08:18:00.961768Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpecAugment(nn.Module):\n",
    "    def __init__(self, \n",
    "                 time_mask_param: int, \n",
    "                 freq_mask_param: int,\n",
    "                 p_time_mask=1.0,\n",
    "                 p_freq_mask=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert 0 <= p_time_mask <= 1.0\n",
    "        assert 0 <= p_freq_mask <= 1.0\n",
    "        \n",
    "        self.__time_mask_param = time_mask_param\n",
    "        self.__freq_mask_param = freq_mask_param\n",
    "        \n",
    "        self.p_time_mask = p_time_mask\n",
    "        self.p_freq_mask = p_freq_mask\n",
    "        \n",
    "        self.time_mask_fun = T.TimeMasking(time_mask_param=time_mask_param)\n",
    "        self.freq_mask_fun = T.FrequencyMasking(freq_mask_param=freq_mask_param)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        _repr = \"SpecAugment(time_mask_param={}, freq_mask_param={})\".format(self.__time_mask_param, \n",
    "                                                                             self.__freq_mask_param)\n",
    "        return _repr\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            for n in range(x.shape[0]):\n",
    "                if torch.rand(1) <= self.p_time_mask:\n",
    "                    x[n] = self.time_mask_fun(x[n].unsqueeze(0))\n",
    "                if torch.rand(1) <= self.p_freq_mask:\n",
    "                    x[n] = self.freq_mask_fun(x[n].unsqueeze(0))\n",
    "            return x\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create class which provide data loading ruls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:18:04.150911Z",
     "iopub.status.busy": "2022-07-03T08:18:04.149873Z",
     "iopub.status.idle": "2022-07-03T08:18:04.167174Z",
     "shell.execute_reply": "2022-07-03T08:18:04.166022Z",
     "shell.execute_reply.started": "2022-07-03T08:18:04.150870Z"
    }
   },
   "outputs": [],
   "source": [
    "class DatasetAudio(Dataset):\n",
    "    def __init__(self, \n",
    "                 sounds_list,\n",
    "                 extractor,\n",
    "                 batch_size:int,\n",
    "                 mode=\"train\",\n",
    "                 length:tuple=None  # you can use it as dinamic length of extractor\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        assert mode in [\"train\", \"test\", \"valid\"]\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.sounds_list = sounds_list\n",
    "        self.extractor = extractor\n",
    "        if mode == \"train\":\n",
    "            self.batch_size = batch_size\n",
    "        else:\n",
    "            self.batch_size = 1\n",
    "        self.length = length\n",
    "        self.id_map = {\"human\": 0.0, \"spoof\": 1.0}\n",
    "        \n",
    "        print(\"Init DatasetAudio with batch size: {:d}\".format(self.batch_size))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sounds_list) // self.batch_size\n",
    "    \n",
    "    def get_item_train(self, index):\n",
    "        if self.batch_size is None:\n",
    "            sound_item = self.sounds_list[index]\n",
    "            x = self.extractor(sound=sound_item)\n",
    "            y = [self.id_map[sound_item.sound_id]]\n",
    "            y = torch.FloatTensor(y)\n",
    "        else:\n",
    "            sounds_batch = random.choices(self.sounds_list, k=self.batch_size)\n",
    "            x = list()\n",
    "            y = list()\n",
    "            for sound_item in sounds_batch:\n",
    "                x.append(self.extractor(sound=sound_item))\n",
    "                y.append(self.id_map[sound_item.sound_id])\n",
    "            x = torch.stack(x)\n",
    "            y = torch.FloatTensor(y).unsqueeze(1)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def get_item_valid(self, index):\n",
    "        sound_item = self.sounds_list[index]\n",
    "        x = self.extractor(sound=sound_item)\n",
    "        y = [self.id_map[sound_item.sound_id]]\n",
    "        y = torch.FloatTensor(y)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def get_item_test(self, index):\n",
    "        sound_item = self.sounds_list[index]\n",
    "        x = self.extractor(sound=sound_item)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == \"train\":\n",
    "            return self.get_item_train(index)\n",
    "        elif self.mode == \"valid\":\n",
    "            return self.get_item_valid(index=index)\n",
    "        elif self.mode == \"test\":\n",
    "            return self.get_item_test(index=index)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:18:12.894786Z",
     "iopub.status.busy": "2022-07-03T08:18:12.894383Z",
     "iopub.status.idle": "2022-07-03T08:18:12.920567Z",
     "shell.execute_reply": "2022-07-03T08:18:12.919559Z",
     "shell.execute_reply.started": "2022-07-03T08:18:12.894745Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 loss,\n",
    "                 optimizer_fn,\n",
    "                 autocast:bool = False,\n",
    "                 validation=None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer_fn(self.parameters())\n",
    "        self.validation = validation\n",
    "        \n",
    "        self.autocast = autocast\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        self.meter_loss = AverageMeter(name=\"loss\", momentum=0.9)\n",
    "        self.meter_accuracy = AverageMeter(name=\"accuracy\", momentum=0.9)\n",
    "        self.meter_speed = AverageMeter(name=\"speed\", momentum=0.5)\n",
    "        self.timer = Timer()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.meter_loss.reset()\n",
    "        self.meter_accuracy.reset()\n",
    "        self.meter_speed.reset()\n",
    "        self.train()\n",
    "        self.timer.tic()\n",
    "        \n",
    "    def show(self, epoch, n_step, steps_total, loss, accuracy):\n",
    "        duration = self.timer.tictoc()\n",
    "        speed = 1.0 / duration\n",
    "        eta = (steps_total - n_step) / speed\n",
    "        \n",
    "        self.meter_loss.step(loss)\n",
    "        self.meter_accuracy.step(accuracy)\n",
    "        self.meter_speed.step(speed)\n",
    "        \n",
    "        info = \" \".join(\n",
    "            [\n",
    "                \"\\repoch-{:d} ->\".format(epoch),\n",
    "                \"{:d}\\{:d}\".format(n_step, steps_total),\n",
    "                \"loss: {:0.3f}\".format(self.meter_loss.get()),\n",
    "                \"accuracy: {:0.3f}\".format(self.meter_accuracy.get()),\n",
    "                \"speed: {:0.1f} it/sec\".format(self.meter_speed.get()),\n",
    "                \"ETA: {:0.1f}\".format(eta)\n",
    "            ])\n",
    "        print(info, end='\\r', flush=True)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.model(x)\n",
    "            pred = self.loss.predict(out)\n",
    "        self.train()\n",
    "        return pred\n",
    "        \n",
    "    def step_epoch(self, num_epoch, dataloader):\n",
    "        self.reset()\n",
    "        \n",
    "        iterator = iter(dataloader)\n",
    "        steps_epoch = len(iterator)\n",
    "        \n",
    "        for n_step in range(steps_epoch):\n",
    "            self.zero_grad()\n",
    "            loss, acc = self.step(iterator)\n",
    "            \n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            loss_detached = float(loss.detach().cpu())\n",
    "            accuracy = float(acc.cpu())\n",
    "            self.show(epoch=num_epoch,\n",
    "                      n_step=n_step + 1,\n",
    "                      steps_total=steps_epoch,\n",
    "                      loss=loss_detached,\n",
    "                      accuracy=accuracy\n",
    "                      )\n",
    "        if self.validation is not None:\n",
    "            if (num_epoch % self.validation.period) == 0:\n",
    "                *_, auc_score, logloss = self.validation(self)\n",
    "                print(\"validation auc score: {:0.3f}\".format(auc_score))\n",
    "                print(\"validation logloss: {:0.3f}\".format(logloss))\n",
    "            \n",
    "    def step(self, iterator):\n",
    "        x, y = next(iterator)\n",
    "        x = x.cuda()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=self.autocast):\n",
    "            out = self.model.forward(x)\n",
    "            l = self.loss.forward(out, y.to(out.device))\n",
    "            y_pred = self.loss.predict(out.detach())\n",
    "        acc = accuracy(y_pred, y.to(y_pred.device))\n",
    "        \n",
    "        return l, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester\n",
    "Make test and validation in single class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:19:05.659351Z",
     "iopub.status.busy": "2022-07-03T08:19:05.658953Z",
     "iopub.status.idle": "2022-07-03T08:19:05.677858Z",
     "shell.execute_reply": "2022-07-03T08:19:05.676734Z",
     "shell.execute_reply.started": "2022-07-03T08:19:05.659321Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, dataset, save_folder, mode, period=1):\n",
    "        assert mode in [\"test\", \"valid\"]\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.dataset = dataset\n",
    "        self.save_folder = save_folder\n",
    "        self.best_auc = 0.0\n",
    "        self.best_logloss = np.inf\n",
    "        self.period = period\n",
    "        \n",
    "        if self.save_folder is not None:\n",
    "            os.makedirs(self.save_folder, exist_ok=True)\n",
    "        \n",
    "    def get_loader(self):\n",
    "        loader = DataLoader(dataset=self.dataset,\n",
    "                            shuffle=False,\n",
    "                            batch_size=None,\n",
    "                            num_workers=8,\n",
    "                            prefetch_factor=1,\n",
    "                            persistent_workers=False,\n",
    "                            pin_memory=True)\n",
    "        return loader\n",
    "        \n",
    "    def call_valid(self, engine):\n",
    "        loader = self.get_loader()\n",
    "        iterator = iter(loader)\n",
    "        \n",
    "        y_true = list()\n",
    "        y_pred = list()\n",
    "        for x, y in tqdm(iterator, desc=\"evaluating\"):\n",
    "            y_true.append(y.squeeze().cpu())\n",
    "            y_pred.append(engine.predict(x.cuda()).squeeze().cpu().numpy())\n",
    "        y_true = np.hstack(y_true)\n",
    "        y_pred = np.hstack(y_pred)\n",
    "\n",
    "        auc_score = roc_auc_score(y_true, y_pred)\n",
    "        logloss = log_loss(y_true, y_pred, eps=1e-4)\n",
    "        \n",
    "        if self.save_folder is not None:\n",
    "            if auc_score > self.best_auc:\n",
    "                self.best_auc = auc_score\n",
    "                file_save = os.path.join(self.save_folder, \"best-auc.torch\")\n",
    "                torch.save(engine.state_dict(), file_save)\n",
    "                print(\"save model to {} with best auc score {:0.3f}\".format(file_save, auc_score))\n",
    "                \n",
    "            if logloss < self.best_logloss:\n",
    "                self.best_logloss = logloss\n",
    "                file_save = os.path.join(self.save_folder, \"best-logloss.torch\")\n",
    "                torch.save(engine.state_dict(), file_save)\n",
    "                print(\"save model to {} with best logloss {:0.3f}\".format(file_save, logloss))\n",
    "        \n",
    "        del loader\n",
    "        gc.collect()\n",
    "        \n",
    "        return (y_true, y_pred), auc_score, logloss\n",
    "        \n",
    "    def call_test(self, engine):\n",
    "        loader = self.get_loader()\n",
    "        iterator = iter(loader)\n",
    "        \n",
    "        y_pred = list()\n",
    "        for x in tqdm(iterator):\n",
    "            proba = engine.predict(x.cuda()).cpu()\n",
    "            y_pred.append(float(proba))\n",
    "        return y_pred\n",
    "    \n",
    "    def __call__(self, engine):\n",
    "        if self.mode == \"valid\":\n",
    "            return self.call_valid(engine=engine)\n",
    "        elif self.mode == \"test\":\n",
    "            return self.call_test(engine=engine)\n",
    "        else:\n",
    "            raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:07:23.254069Z",
     "iopub.status.busy": "2022-07-02T13:07:23.253519Z",
     "iopub.status.idle": "2022-07-02T13:07:23.262876Z",
     "shell.execute_reply": "2022-07-02T13:07:23.261678Z",
     "shell.execute_reply.started": "2022-07-02T13:07:23.254021Z"
    }
   },
   "outputs": [],
   "source": [
    "os.path.join(par_dir, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:19:10.466261Z",
     "iopub.status.busy": "2022-07-03T08:19:10.465732Z",
     "iopub.status.idle": "2022-07-03T08:19:10.471428Z",
     "shell.execute_reply": "2022-07-03T08:19:10.470392Z",
     "shell.execute_reply.started": "2022-07-03T08:19:10.466209Z"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLERATE = 16000\n",
    "DITHERING = 1e-7\n",
    "dim_embeddings = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:19:12.904302Z",
     "iopub.status.busy": "2022-07-03T08:19:12.903900Z",
     "iopub.status.idle": "2022-07-03T08:19:12.911453Z",
     "shell.execute_reply": "2022-07-03T08:19:12.910637Z",
     "shell.execute_reply.started": "2022-07-03T08:19:12.904271Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "par_dir = \"/kaggle/input/made-voice-anti-spoofing-parctice/\"\n",
    "save_folder = \"results\"\n",
    "data_path_train = os.path.join(par_dir, \"train\")\n",
    "print(data_path_train)\n",
    "\n",
    "data_path_test = os.path.join(par_dir, \"test\")\n",
    "print(data_path_test)\n",
    "\n",
    "meta_path = os.path.join(par_dir, \"train.csv\")\n",
    "print(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T09:45:06.521721Z",
     "iopub.status.busy": "2022-07-03T09:45:06.520901Z",
     "iopub.status.idle": "2022-07-03T09:45:06.526980Z",
     "shell.execute_reply": "2022-07-03T09:45:06.526101Z",
     "shell.execute_reply.started": "2022-07-03T09:45:06.521681Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_data_path_train = \"../input/musan-noise/musan/speech/librivox/\"\n",
    "extra_data_path_train_2 = \"../input/musan-noise/musan/speech/us-gov/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:44:05.195875Z",
     "iopub.status.busy": "2022-07-03T08:44:05.195509Z",
     "iopub.status.idle": "2022-07-03T08:44:05.201960Z",
     "shell.execute_reply": "2022-07-03T08:44:05.200864Z",
     "shell.execute_reply.started": "2022-07-03T08:44:05.195846Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_files(directory, pattern='**/*.wav'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    return glob(os.path.join(directory, pattern), recursive=True)  # Return a list of paths matching a pathname pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:19:17.348003Z",
     "iopub.status.busy": "2022-07-03T08:19:17.347634Z",
     "iopub.status.idle": "2022-07-03T08:20:12.503461Z",
     "shell.execute_reply": "2022-07-03T08:20:12.502566Z",
     "shell.execute_reply.started": "2022-07-03T08:19:17.347974Z"
    }
   },
   "outputs": [],
   "source": [
    "files_train = sorted(find_files(data_path_train, pattern=\"**/*.wav\")) # Recursively finds all files matching the pattern.\n",
    "files_test = sorted(find_files(data_path_test, pattern=\"**/*.wav\"))   # Recursively finds all files matching the pattern.\n",
    "\n",
    "print(files_train[0])\n",
    "print(files_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:38:57.185460Z",
     "iopub.status.busy": "2022-07-03T11:38:57.184891Z",
     "iopub.status.idle": "2022-07-03T11:38:57.216620Z",
     "shell.execute_reply": "2022-07-03T11:38:57.215140Z",
     "shell.execute_reply.started": "2022-07-03T11:38:57.185420Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_files_train = sorted(find_files(extra_data_path_train, \"**/*.wav\"))\n",
    "extra_files_train_2 = sorted(find_files(extra_data_path_train_2, \"**/*.wav\"))\n",
    "extra_files_train += extra_files_train_2\n",
    "len(extra_files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T10:57:49.345316Z",
     "iopub.status.busy": "2022-07-03T10:57:49.344829Z",
     "iopub.status.idle": "2022-07-03T10:57:49.352927Z",
     "shell.execute_reply": "2022-07-03T10:57:49.351282Z",
     "shell.execute_reply.started": "2022-07-03T10:57:49.345273Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "window  = librosa.filters.get_window(\"tukey\", 16_000 * 5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T10:59:22.684850Z",
     "iopub.status.busy": "2022-07-03T10:59:22.684416Z",
     "iopub.status.idle": "2022-07-03T10:59:23.455558Z",
     "shell.execute_reply": "2022-07-03T10:59:23.454027Z",
     "shell.execute_reply.started": "2022-07-03T10:59:22.684816Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir extra_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T10:59:59.873596Z",
     "iopub.status.busy": "2022-07-03T10:59:59.872783Z",
     "iopub.status.idle": "2022-07-03T11:02:17.139239Z",
     "shell.execute_reply": "2022-07-03T11:02:17.137631Z",
     "shell.execute_reply.started": "2022-07-03T10:59:59.873546Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "name_pat = \"extra_file_\"\n",
    "duration = 5 \n",
    "sr = 16_000\n",
    "for file in extra_files_train:\n",
    "    if i > 30_000:\n",
    "        break\n",
    "    sound, _ = librosa.load(file, sr = None)\n",
    "    length = len(sound) // (duration * sr)\n",
    "    for k in range(length-1):\n",
    "        name = name_pat + str(i)\n",
    "        path = \"extra_files/\" + name\n",
    "        aud = sound[sr*duration*k : sr*duration*(k+1)] * window\n",
    "        sf.write(path + \".wav\", aud, sr)\n",
    "        i +=1\n",
    "        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:07:18.780568Z",
     "iopub.status.busy": "2022-07-03T11:07:18.779166Z",
     "iopub.status.idle": "2022-07-03T11:07:18.793614Z",
     "shell.execute_reply": "2022-07-03T11:07:18.792079Z",
     "shell.execute_reply.started": "2022-07-03T11:07:18.780517Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "Audio('extra_files/extra_file_29000.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:08:45.109103Z",
     "iopub.status.busy": "2022-07-03T11:08:45.108619Z",
     "iopub.status.idle": "2022-07-03T11:08:45.253604Z",
     "shell.execute_reply": "2022-07-03T11:08:45.252393Z",
     "shell.execute_reply.started": "2022-07-03T11:08:45.109060Z"
    }
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv(meta_path, index_col=\"filename\").to_dict()[\"class_id\"]\n",
    "meta['sample-00000.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:24:19.027291Z",
     "iopub.status.busy": "2022-07-03T08:24:19.026563Z",
     "iopub.status.idle": "2022-07-03T08:24:19.036413Z",
     "shell.execute_reply": "2022-07-03T08:24:19.035512Z",
     "shell.execute_reply.started": "2022-07-03T08:24:19.027246Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sound:\n",
    "    def __init__(self, \n",
    "                 path, \n",
    "                 sound_id=None,\n",
    "                 meta=None, \n",
    "                 samplerate=None):\n",
    "        self.path = str(path)\n",
    "        self.sound_id = sound_id\n",
    "        self.samplerate = samplerate\n",
    "        self.meta = meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:24:21.223655Z",
     "iopub.status.busy": "2022-07-03T08:24:21.222917Z",
     "iopub.status.idle": "2022-07-03T08:24:21.229264Z",
     "shell.execute_reply": "2022-07-03T08:24:21.227976Z",
     "shell.execute_reply.started": "2022-07-03T08:24:21.223601Z"
    }
   },
   "outputs": [],
   "source": [
    "def stem(file):\n",
    "    return file.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T10:37:20.273818Z",
     "iopub.status.busy": "2022-07-03T10:37:20.272751Z",
     "iopub.status.idle": "2022-07-03T10:37:20.281251Z",
     "shell.execute_reply": "2022-07-03T10:37:20.280217Z",
     "shell.execute_reply.started": "2022-07-03T10:37:20.273766Z"
    }
   },
   "outputs": [],
   "source": [
    "files_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:07:54.384344Z",
     "iopub.status.busy": "2022-07-03T11:07:54.383492Z",
     "iopub.status.idle": "2022-07-03T11:07:54.553006Z",
     "shell.execute_reply": "2022-07-03T11:07:54.551781Z",
     "shell.execute_reply.started": "2022-07-03T11:07:54.384304Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_files_train = sorted(find_files(\"extra_files\", pattern=\"**/*.wav\"))\n",
    "len(extra_files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:08:51.072573Z",
     "iopub.status.busy": "2022-07-03T11:08:51.072133Z",
     "iopub.status.idle": "2022-07-03T11:08:51.226049Z",
     "shell.execute_reply": "2022-07-03T11:08:51.224444Z",
     "shell.execute_reply.started": "2022-07-03T11:08:51.072537Z"
    }
   },
   "outputs": [],
   "source": [
    "sounds = list()\n",
    "for f in files_train:\n",
    "    sounds.append(Sound(path=f, sound_id=meta[stem(f)]))\n",
    "\n",
    "for f in extra_files_train:\n",
    "    sounds.append(Sound(path=f, sound_id=\"human\"))\n",
    "\n",
    "sounds = np.array(sounds)\n",
    "np.random.shuffle(sounds)\n",
    "sounds = list(sounds)\n",
    "    \n",
    "sounds_test = list()\n",
    "for f in files_test:\n",
    "    sounds_test.append(Sound(path=f, sound_id=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:08:57.870130Z",
     "iopub.status.busy": "2022-07-03T11:08:57.868977Z",
     "iopub.status.idle": "2022-07-03T11:08:57.876843Z",
     "shell.execute_reply": "2022-07-03T11:08:57.875919Z",
     "shell.execute_reply.started": "2022-07-03T11:08:57.870086Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sounds[1].path)\n",
    "print(sounds[1].sound_id)\n",
    "print(sounds[1].samplerate)\n",
    "print(sounds[1].meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:09:08.822325Z",
     "iopub.status.busy": "2022-07-03T11:09:08.821614Z",
     "iopub.status.idle": "2022-07-03T11:09:08.828687Z",
     "shell.execute_reply": "2022-07-03T11:09:08.827662Z",
     "shell.execute_reply.started": "2022-07-03T11:09:08.822278Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:09:32.036243Z",
     "iopub.status.busy": "2022-07-03T11:09:32.035796Z",
     "iopub.status.idle": "2022-07-03T11:09:32.053523Z",
     "shell.execute_reply": "2022-07-03T11:09:32.052466Z",
     "shell.execute_reply.started": "2022-07-03T11:09:32.036203Z"
    }
   },
   "outputs": [],
   "source": [
    "sounds_train, sounds_valid = train_test_split(sounds, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:26:24.823786Z",
     "iopub.status.busy": "2022-07-02T13:26:24.823380Z",
     "iopub.status.idle": "2022-07-02T13:26:24.828640Z",
     "shell.execute_reply": "2022-07-02T13:26:24.827648Z",
     "shell.execute_reply.started": "2022-07-02T13:26:24.823753Z"
    }
   },
   "outputs": [],
   "source": [
    "# sounds_train, sounds_valid, sounds_test - a list of Sound objects, with atributies: path, id, samp_rate, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:09:45.804648Z",
     "iopub.status.busy": "2022-07-03T11:09:45.804211Z",
     "iopub.status.idle": "2022-07-03T11:09:45.813660Z",
     "shell.execute_reply": "2022-07-03T11:09:45.812318Z",
     "shell.execute_reply.started": "2022-07-03T11:09:45.804612Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sounds_train), len(sounds_valid), len(sounds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Extractors\n",
    "Be carefull, extractors for train and test is different, but some parameters like \"dithering\" or \"sameple rate\" must be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:09:59.727553Z",
     "iopub.status.busy": "2022-07-03T11:09:59.726888Z",
     "iopub.status.idle": "2022-07-03T11:09:59.740590Z",
     "shell.execute_reply": "2022-07-03T11:09:59.739412Z",
     "shell.execute_reply.started": "2022-07-03T11:09:59.727515Z"
    }
   },
   "outputs": [],
   "source": [
    "class RawExtractor:\n",
    "    def __init__(self,\n",
    "                 length,\n",
    "                 dithering: float=None,\n",
    "                 samplerate: int=16000,\n",
    "                 normed: bool =False\n",
    "                 ):\n",
    "        self.dithering = dithering\n",
    "        self.length = length\n",
    "        self.samplerate = samplerate\n",
    "        self.normed = normed       \n",
    "        self.audio_loader = AudioReader(samplerate=self.samplerate,\n",
    "                                        length=length)\n",
    "        \n",
    "        if length is not None:\n",
    "            # padding\n",
    "            self.audio_padder = AudioPadder(mode=\"constant\",\n",
    "                                            length=length,\n",
    "                                            random=True\n",
    "                                            )\n",
    "        else:\n",
    "            self.audio_padder = None\n",
    "    \n",
    "    # adding noise\n",
    "    def make_dithering(self, audio):\n",
    "        return audio + self.dithering * torch.rand_like(audio)\n",
    "    \n",
    "    \n",
    "    def normalize(self, audio):\n",
    "        audio = audio - torch.mean(audio)\n",
    "        audio = audio / (torch.std(audio) + 1e-6)\n",
    "        return audio\n",
    "        \n",
    "    def __call__(self, sound):\n",
    "        if not isinstance(sound, str):\n",
    "            sound = sound.path\n",
    "        \n",
    "        # loading audio\n",
    "        audio = self.audio_loader(file=sound, length=self.length)\n",
    "        \n",
    "        # normalise\n",
    "        if self.normed:\n",
    "            audio = self.normalize(audio)\n",
    "        \n",
    "        # add padding\n",
    "        if self.audio_padder is not None:\n",
    "            audio = self.audio_padder(x=audio, length=self.length)\n",
    "        \n",
    "        # add noise\n",
    "        if self.dithering is not None:\n",
    "            audio = self.make_dithering(audio)\n",
    "            \n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T08:24:34.309265Z",
     "iopub.status.busy": "2022-07-03T08:24:34.308374Z",
     "iopub.status.idle": "2022-07-03T08:24:34.316391Z",
     "shell.execute_reply": "2022-07-03T08:24:34.315474Z",
     "shell.execute_reply.started": "2022-07-03T08:24:34.309210Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor_audio_train = RawExtractor(\n",
    "    length=int(SAMPLERATE * 3.0),\n",
    "    dithering=1e-6,\n",
    "    samplerate=16000,\n",
    "    normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:10:24.568534Z",
     "iopub.status.busy": "2022-07-03T11:10:24.567738Z",
     "iopub.status.idle": "2022-07-03T11:10:24.574877Z",
     "shell.execute_reply": "2022-07-03T11:10:24.573562Z",
     "shell.execute_reply.started": "2022-07-03T11:10:24.568496Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor_audio_test = RawExtractor(\n",
    "    length=None,\n",
    "    dithering=DITHERING,\n",
    "    samplerate=16000,\n",
    "    normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:10:09.180861Z",
     "iopub.status.busy": "2022-07-03T11:10:09.180116Z",
     "iopub.status.idle": "2022-07-03T11:10:09.197024Z",
     "shell.execute_reply": "2022-07-03T11:10:09.196094Z",
     "shell.execute_reply.started": "2022-07-03T11:10:09.180804Z"
    }
   },
   "outputs": [],
   "source": [
    "class MFCC(nn.Module):\n",
    "    def __init__(self,\n",
    "                 win_length: int,\n",
    "                 hop_length: int,\n",
    "                 n_fft: int, \n",
    "                 n_mels: int, \n",
    "                 n_mfcc: int,\n",
    "                 f_min: float, \n",
    "                 f_max: float, \n",
    "                 sample_rate: int,\n",
    "                 log_mels=False,\n",
    "                 instancenorm=False\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max\n",
    "        self.n_mels = n_mels\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window_fn = torch.hamming_window\n",
    "        self.log_mels = log_mels\n",
    "        \n",
    "        mfcc = torchaudio.transforms.MFCC\n",
    "        self.extractor = mfcc(sample_rate = self.sample_rate, \n",
    "                              n_mfcc = self.n_mfcc, \n",
    "                              log_mels = self.log_mels, # whether to use log-mel spectrograms instead of db-scaled.\n",
    "                              dct_type = 2,             # type of iscrete cosine transform\n",
    "                              melkwargs={'n_mels': self.n_mels, \n",
    "                                         'n_fft':  self.n_fft, \n",
    "                                         'win_length': self.win_length, \n",
    "                                         'hop_length': self.hop_length, \n",
    "                                         'f_min': self.f_min,  # max frequancy\n",
    "                                         'f_max': self.f_max,  # min frequancy\n",
    "                                         'window_fn': self.window_fn}) # hamming window\n",
    "        \n",
    "        if instancenorm:\n",
    "            self.instancenorm   = nn.InstanceNorm1d(self.n_mels) # Applies Instance Normalization over a 2D (unbatched)\n",
    "        else:\n",
    "            self.instancenorm = None\n",
    "        \n",
    "    def dim(self):\n",
    "        return self.n_mfcc\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            if x.dim() == 3:\n",
    "                x = x.squeeze(1)\n",
    "\n",
    "            f = self.extractor(x)\n",
    "            if self.instancenorm is not None:\n",
    "                f = self.instancenorm(f)\n",
    "\n",
    "            return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T14:13:51.344871Z",
     "iopub.status.busy": "2022-07-02T14:13:51.344063Z",
     "iopub.status.idle": "2022-07-02T14:13:51.349077Z",
     "shell.execute_reply": "2022-07-02T14:13:51.348281Z",
     "shell.execute_reply.started": "2022-07-02T14:13:51.344830Z"
    }
   },
   "outputs": [],
   "source": [
    "# extractor_spec =Fbank(\n",
    "#     win_length=int(0.025 * SAMPLERATE),\n",
    "#     hop_length=int(0.01 * SAMPLERATE),\n",
    "#     n_fft=512, \n",
    "#     n_mels=64, \n",
    "#     f_min=200, \n",
    "#     f_max=7000, \n",
    "#     sample_rate=SAMPLERATE,\n",
    "#     log_input=True,\n",
    "#     instancenorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:10:35.158182Z",
     "iopub.status.busy": "2022-07-03T11:10:35.157270Z",
     "iopub.status.idle": "2022-07-03T11:10:35.166528Z",
     "shell.execute_reply": "2022-07-03T11:10:35.165228Z",
     "shell.execute_reply.started": "2022-07-03T11:10:35.158135Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor_spec = MFCC(\n",
    "    win_length=int(0.025 * SAMPLERATE),\n",
    "    hop_length=int(0.01 * SAMPLERATE),\n",
    "    n_fft=512,\n",
    "    n_mels=64,\n",
    "    n_mfcc=39, \n",
    "    f_min=200, \n",
    "    f_max=8000, \n",
    "    sample_rate=SAMPLERATE,\n",
    "    log_mels=True,\n",
    "    instancenorm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:10:43.488717Z",
     "iopub.status.busy": "2022-07-03T11:10:43.488286Z",
     "iopub.status.idle": "2022-07-03T11:10:43.498122Z",
     "shell.execute_reply": "2022-07-03T11:10:43.496747Z",
     "shell.execute_reply.started": "2022-07-03T11:10:43.488683Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor_spec.dim(), dim_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:10:48.357517Z",
     "iopub.status.busy": "2022-07-03T11:10:48.356502Z",
     "iopub.status.idle": "2022-07-03T11:10:48.394910Z",
     "shell.execute_reply": "2022-07-03T11:10:48.393370Z",
     "shell.execute_reply.started": "2022-07-03T11:10:48.357456Z"
    }
   },
   "outputs": [],
   "source": [
    "model_base = ECAPA_1KCSBN(\n",
    "    features_dim=extractor_spec.dim(),\n",
    "    dim_out=dim_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:11:13.071784Z",
     "iopub.status.busy": "2022-07-03T12:11:13.070817Z",
     "iopub.status.idle": "2022-07-03T12:11:13.125118Z",
     "shell.execute_reply": "2022-07-03T12:11:13.124106Z",
     "shell.execute_reply.started": "2022-07-03T12:11:13.071727Z"
    }
   },
   "outputs": [],
   "source": [
    "# for noise\n",
    "path_1 = \"../input/musan-noise/musan/noise/free-sound/noise-free-sound-0027.wav\"\n",
    "path_2 = \"../input/musan-noise/musan/noise/sound-bible/noise-sound-bible-0027.wav\"\n",
    "\n",
    "sound, _ = librosa.load(\"../input/made-voice-anti-spoofing-parctice/train/sample-00000.wav\", sr = 16000)\n",
    "noise_1, lr_1 = librosa.load(path_1, sr = None)\n",
    "noise_2, lr_2  = librosa.load(path_2, sr = None)\n",
    "print(lr_1, lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:11:20.667134Z",
     "iopub.status.busy": "2022-07-03T12:11:20.666420Z",
     "iopub.status.idle": "2022-07-03T12:11:20.685572Z",
     "shell.execute_reply": "2022-07-03T12:11:20.684187Z",
     "shell.execute_reply.started": "2022-07-03T12:11:20.667083Z"
    }
   },
   "outputs": [],
   "source": [
    "max(noise_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:11:37.270509Z",
     "iopub.status.busy": "2022-07-03T12:11:37.269557Z",
     "iopub.status.idle": "2022-07-03T12:11:37.287437Z",
     "shell.execute_reply": "2022-07-03T12:11:37.286150Z",
     "shell.execute_reply.started": "2022-07-03T12:11:37.270426Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_noise(sound, noise, alpha = 0.1):\n",
    "    \n",
    "    if len(sound) > len(noise):\n",
    "        pad_with = (len(sound) - len(noise))//2 + 1\n",
    "        noise = np.pad(noise, (pad_with,), mode = \"reflect\") \n",
    "        \n",
    "    max_len = min(len(sound), len(noise))\n",
    "    return sound[:max_len] + alpha*noise[:max_len]\n",
    "\n",
    "noise_sound = make_noise(sound, noise_2)\n",
    "Audio(data = noise_sound, rate = lr_1, autoplay=True, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:15:11.247573Z",
     "iopub.status.busy": "2022-07-03T12:15:11.246460Z",
     "iopub.status.idle": "2022-07-03T12:15:11.375427Z",
     "shell.execute_reply": "2022-07-03T12:15:11.374136Z",
     "shell.execute_reply.started": "2022-07-03T12:15:11.247527Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_folder_1 = \"../input/musan-noise/musan/noise/free-sound\"\n",
    "noise_folder_2 = \"../input/musan-noise/musan/noise/sound-bible\"\n",
    "\n",
    "\n",
    "noise_files = sorted(find_files(noise_folder_1, pattern=\"**/*.wav\")) # Recursively finds all files matching the pattern.\n",
    "noise_files_2 = sorted(find_files(noise_folder_2, pattern=\"**/*.wav\"))   # Recursively finds all files matching the pattern.\n",
    "\n",
    "\n",
    "noise_files += noise_files_2\n",
    "len(noise_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:17:29.354630Z",
     "iopub.status.busy": "2022-07-03T12:17:29.354189Z",
     "iopub.status.idle": "2022-07-03T12:17:47.887549Z",
     "shell.execute_reply": "2022-07-03T12:17:47.886145Z",
     "shell.execute_reply.started": "2022-07-03T12:17:29.354595Z"
    }
   },
   "outputs": [],
   "source": [
    "noises_array = []\n",
    "for noise_file in noise_files:\n",
    "    noise_array, _ = librosa.load(noise_file, sr = None)\n",
    "    noises_array.append(noise_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNoise(nn.Module):\n",
    "    \n",
    "    def __init__(self, noise_data):\n",
    "        super().__init__()\n",
    "        self.noise_data = noise_data\n",
    "        self.data_size = len(noise_data)\n",
    "        self.max_len = max(map(len, self.noise_data))\n",
    "        \n",
    "     \n",
    "    def make_noise(self, sound, noise, alpha =1):\n",
    "        \n",
    "        if len(sound) > len(noise):\n",
    "            pad_with = (len(sound) - len(noise))//2 + 1\n",
    "            noise = np.pad(noise, (pad_with,), mode = \"reflect\") \n",
    "       \n",
    "        else:\n",
    "            noise = noise[:-len(sound)]\n",
    "        print(sound.shape, noise.shape)    \n",
    "        max_len = min(len(sound), len(noise))\n",
    "        print(sound.shape, noise.shape) \n",
    "        return sound[:self.max_len] + alpha*noise[:self.max_len]\n",
    "    \n",
    "    def forward(self, sound_batch):\n",
    "        if self.training:\n",
    "            batch_size = sound_batch.shape[0]\n",
    "            rand_idx = np.random.randint(0, self.data_size, batch_size)\n",
    "            i = 0\n",
    "\n",
    "            for sound, idx in zip(sound_batch, rand_idx):\n",
    "                sound = self.make_noise(sound[0].detach().numpy(), self.noise_data[idx])\n",
    "                sound_batch[i][1] = sound\n",
    "                i += 1\n",
    "            return sound_batch\n",
    "        \n",
    "        else:\n",
    "            return sound_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:18:04.817577Z",
     "iopub.status.busy": "2022-07-03T12:18:04.816404Z",
     "iopub.status.idle": "2022-07-03T12:18:04.824858Z",
     "shell.execute_reply": "2022-07-03T12:18:04.823711Z",
     "shell.execute_reply.started": "2022-07-03T12:18:04.817534Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyNoise(nn.Module):\n",
    "    \n",
    "    def __init_(self, noise_data):\n",
    "        super().__init__()\n",
    "        self.noise_data = noise_data\n",
    "        self.data_size = len(noise_data)\n",
    "     \n",
    "    def make_noise(self, sound, noise, alpha = 0.1):\n",
    "    \n",
    "        if len(sound) > len(noise):\n",
    "            pad_with = (len(sound) - len(noise))//2 + 1\n",
    "            noise = np.pad(noise, (pad_with,), mode = \"reflect\") \n",
    "        \n",
    "        max_len = min(len(sound), len(noise))\n",
    "        return sound[:max_len] + alpha*noise[:max_len]\n",
    "    \n",
    "    def forward(self, sound_batch):\n",
    "        if self.training:\n",
    "            rand_idx = torch.randint(0, self.data_noise)\n",
    "            noise = self.noise_data[rand_idx]\n",
    "            noise_sound = sound_batch + noise\n",
    "            \n",
    "            return noise_sound\n",
    "        else:  \n",
    "            return sound_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T12:20:40.238600Z",
     "iopub.status.busy": "2022-07-03T12:20:40.238130Z",
     "iopub.status.idle": "2022-07-03T12:20:40.268574Z",
     "shell.execute_reply": "2022-07-03T12:20:40.266076Z",
     "shell.execute_reply.started": "2022-07-03T12:20:40.238560Z"
    }
   },
   "outputs": [],
   "source": [
    "class NoiseAugment(nn.Module):\n",
    "    def __init__(self, snr_db_min: float, snr_db_max: float, dim=-1):\n",
    "        super().__init__()\n",
    "        assert snr_db_min < snr_db_max\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.snr_db_min = snr_db_min   # min value in decibals to add to the signal as a noise\n",
    "        self.snr_db_max = snr_db_max   # max value in decibals to add to the signal as a noise\n",
    "        self.snr_gap = snr_db_max - snr_db_min\n",
    "        \n",
    "    @staticmethod\n",
    "    def db_2_mag(db):\n",
    "        return 20 ** (db / 20) # conver decibals to magnitude\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        # x = [batch_size, 1, len_wave]\n",
    "        if self.training:\n",
    "            snr_db = self.snr_db_min + torch.rand(x.shape[0]) * self.snr_gap   # get random value between max and min\n",
    "            snr_linear = self.db_2_mag(snr_db).to(x.dtype).to(x.device)        # convert to magnitude\n",
    "            # snr_linear = [batch_size]\n",
    "            std_x = torch.std(x, dim=self.dim, keepdims=True)\n",
    "            # std_x.squeeze() = [batch_size]\n",
    "            scale = std_x.squeeze() / snr_linear\n",
    "            # scale = [batch_size]\n",
    "            scale = scale.unsqueeze(1).unsqueeze(1)\n",
    "            # scale = [batch_size, 1, 1]\n",
    "            return x + scale * torch.rand_like(x).to(x.dtype).to(x.device) # x = [batch_size, 1, len_wave]\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "        \n",
    "ex_wave = batch_to_check[:2]\n",
    "print(ex_wave.shape)\n",
    "\n",
    "ex_noise = NoiseAugment(snr_db_min=12, snr_db_max=20)\n",
    "noise_out = ex_noise(torch.tensor(sound))\n",
    "print(noise_out.shape)\n",
    "\n",
    "# plt.plot(ex_wave[0, :100])\n",
    "# plt.plot(noise_out[0, 0, :100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:10:57.690311Z",
     "iopub.status.busy": "2022-07-03T11:10:57.689239Z",
     "iopub.status.idle": "2022-07-03T11:10:57.702187Z",
     "shell.execute_reply": "2022-07-03T11:10:57.700910Z",
     "shell.execute_reply.started": "2022-07-03T11:10:57.690267Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpecAugment(nn.Module):\n",
    "    def __init__(self, \n",
    "                 time_mask_param: int, \n",
    "                 freq_mask_param: int,\n",
    "                 p_time_mask=1.0,\n",
    "                 p_freq_mask=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert 0 <= p_time_mask <= 1.0\n",
    "        assert 0 <= p_freq_mask <= 1.0\n",
    "        \n",
    "        self.__time_mask_param = time_mask_param\n",
    "        self.__freq_mask_param = freq_mask_param\n",
    "        \n",
    "        self.p_time_mask = p_time_mask\n",
    "        self.p_freq_mask = p_freq_mask\n",
    "        \n",
    "        self.time_mask_fun = T.TimeMasking(time_mask_param=time_mask_param)       # Apply masking to a spectrogram in the time domain\n",
    "        self.freq_mask_fun = T.FrequencyMasking(freq_mask_param=freq_mask_param)  # Apply masking to a spectrogram in the frequency domain.\n",
    "        \n",
    "    def __repr__(self):\n",
    "        _repr = \"SpecAugment(time_mask_param={}, freq_mask_param={})\".format(self.__time_mask_param, \n",
    "                                                                             self.__freq_mask_param)\n",
    "        return _repr\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            for n in range(x.shape[0]):\n",
    "                if torch.rand(1) <= self.p_time_mask:\n",
    "                    x[n] = self.time_mask_fun(x[n].unsqueeze(0))\n",
    "                if torch.rand(1) <= self.p_freq_mask:\n",
    "                    x[n] = self.freq_mask_fun(x[n].unsqueeze(0))\n",
    "            return x\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:11:04.576002Z",
     "iopub.status.busy": "2022-07-03T11:11:04.575166Z",
     "iopub.status.idle": "2022-07-03T11:11:04.582733Z",
     "shell.execute_reply": "2022-07-03T11:11:04.581419Z",
     "shell.execute_reply.started": "2022-07-03T11:11:04.575958Z"
    }
   },
   "outputs": [],
   "source": [
    "features_extractor = nn.Sequential(\n",
    "    NoiseAugment(snr_db_min=12, snr_db_max=20),\n",
    "    extractor_spec,\n",
    "    SpecAugment(time_mask_param=40, freq_mask_param=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:14:00.710975Z",
     "iopub.status.busy": "2022-07-03T11:14:00.709479Z",
     "iopub.status.idle": "2022-07-03T11:14:00.719402Z",
     "shell.execute_reply": "2022-07-03T11:14:00.718107Z",
     "shell.execute_reply.started": "2022-07-03T11:14:00.710910Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    features_extractor,\n",
    "    model_base\n",
    ")\n",
    "loss = BCE(dim=dim_embeddings)\n",
    "optimizer_fn = lambda x: torch.optim.AdamW(x, lr=0.001)\n",
    "# scheduller = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_fn, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:14:06.449478Z",
     "iopub.status.busy": "2022-07-03T11:14:06.449069Z",
     "iopub.status.idle": "2022-07-03T11:14:06.459331Z",
     "shell.execute_reply": "2022-07-03T11:14:06.458235Z",
     "shell.execute_reply.started": "2022-07-03T11:14:06.449446Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = DatasetAudio( \n",
    "    sounds_train,\n",
    "    extractor=extractor_audio_train,\n",
    "    batch_size=64,\n",
    "    mode=\"train\",\n",
    "    length=None)\n",
    "dataset_valid = DatasetAudio( \n",
    "    sounds_valid,\n",
    "    extractor=extractor_audio_test,\n",
    "    batch_size=None,\n",
    "    mode=\"valid\",\n",
    "    length=None)\n",
    "dataset_test = DatasetAudio( \n",
    "    sounds_test,\n",
    "    extractor=extractor_audio_test,\n",
    "    batch_size=None,\n",
    "    mode=\"test\",\n",
    "    length=None)\n",
    "\n",
    "loader_train = DataLoader(dataset=dataset_train,\n",
    "                          batch_size=None,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          prefetch_factor=1,\n",
    "                          persistent_workers=True,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:25:14.623966Z",
     "iopub.status.busy": "2022-07-03T11:25:14.623109Z",
     "iopub.status.idle": "2022-07-03T11:25:14.632748Z",
     "shell.execute_reply": "2022-07-03T11:25:14.631749Z",
     "shell.execute_reply.started": "2022-07-03T11:25:14.623902Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset_train) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:25:26.718002Z",
     "iopub.status.busy": "2022-07-03T11:25:26.716801Z",
     "iopub.status.idle": "2022-07-03T11:25:27.767294Z",
     "shell.execute_reply": "2022-07-03T11:25:27.763582Z",
     "shell.execute_reply.started": "2022-07-03T11:25:26.717942Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = iter(loader_train)\n",
    "batch_to_check = next(iterator)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:25:30.367610Z",
     "iopub.status.busy": "2022-07-03T11:25:30.367013Z",
     "iopub.status.idle": "2022-07-03T11:25:30.381812Z",
     "shell.execute_reply": "2022-07-03T11:25:30.380470Z",
     "shell.execute_reply.started": "2022-07-03T11:25:30.367550Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_to_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:25:38.114603Z",
     "iopub.status.busy": "2022-07-03T11:25:38.113855Z",
     "iopub.status.idle": "2022-07-03T11:25:38.282340Z",
     "shell.execute_reply": "2022-07-03T11:25:38.281083Z",
     "shell.execute_reply.started": "2022-07-03T11:25:38.114564Z"
    }
   },
   "outputs": [],
   "source": [
    "wave = batch_to_check[0]\n",
    "features_clean = features_extractor.eval()(wave)[0].cpu().numpy()\n",
    "features_noisy = features_extractor.train()(wave)[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:06:32.593025Z",
     "iopub.status.busy": "2022-07-02T13:06:32.592163Z",
     "iopub.status.idle": "2022-07-02T13:06:32.606225Z",
     "shell.execute_reply": "2022-07-02T13:06:32.604706Z",
     "shell.execute_reply.started": "2022-07-02T13:06:32.592972Z"
    }
   },
   "outputs": [],
   "source": [
    "features_clean.shape, features_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-03T11:25:46.315256Z",
     "iopub.status.busy": "2022-07-03T11:25:46.314760Z",
     "iopub.status.idle": "2022-07-03T11:25:48.997717Z",
     "shell.execute_reply": "2022-07-03T11:25:48.996393Z",
     "shell.execute_reply.started": "2022-07-03T11:25:46.315223Z"
    }
   },
   "outputs": [],
   "source": [
    "iterator = iter(loader_train)\n",
    "batch_to_check = next(iterator)[0]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for n in range(8):\n",
    "    wave = batch_to_check[n]\n",
    "    features_clean = features_extractor.eval()(wave)[0].cpu().numpy()\n",
    "    features_noisy = features_extractor.train()(wave)[0].cpu().numpy()\n",
    "\n",
    "    plt.subplot(8, 2, 2 * n + 1)\n",
    "    plt.pcolormesh(features_clean)\n",
    "    plt.subplot(8, 2, 2 * n + 2)\n",
    "    plt.pcolormesh(features_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Testers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T11:22:12.154479Z",
     "iopub.status.busy": "2022-07-02T11:22:12.154116Z",
     "iopub.status.idle": "2022-07-02T11:22:12.176027Z",
     "shell.execute_reply": "2022-07-02T11:22:12.175085Z",
     "shell.execute_reply.started": "2022-07-02T11:22:12.154449Z"
    }
   },
   "outputs": [],
   "source": [
    "validation = Tester(\n",
    "    dataset=dataset_valid,\n",
    "    period=1,\n",
    "    save_folder=save_folder,\n",
    "    mode=\"valid\"\n",
    "    )\n",
    "evaluation = Tester(\n",
    "    dataset=dataset_test,\n",
    "    period=None,\n",
    "    save_folder=None,\n",
    "    mode=\"test\"\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    autocast=False,\n",
    "    validation=validation,\n",
    "    optimizer_fn=optimizer_fn).cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T11:22:22.033799Z",
     "iopub.status.busy": "2022-07-02T11:22:22.033448Z",
     "iopub.status.idle": "2022-07-02T11:57:09.273178Z",
     "shell.execute_reply": "2022-07-02T11:57:09.2721Z",
     "shell.execute_reply.started": "2022-07-02T11:22:22.033769Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "for n in range(n_epochs):\n",
    "    trainer.step_epoch(n, dataloader=loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T11:58:15.278731Z",
     "iopub.status.busy": "2022-07-02T11:58:15.278366Z",
     "iopub.status.idle": "2022-07-02T11:58:15.323507Z",
     "shell.execute_reply": "2022-07-02T11:58:15.322602Z",
     "shell.execute_reply.started": "2022-07-02T11:58:15.278699Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_1_mfcc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T12:02:45.830729Z",
     "iopub.status.busy": "2022-07-02T12:02:45.830347Z",
     "iopub.status.idle": "2022-07-02T12:02:46.536981Z",
     "shell.execute_reply": "2022-07-02T12:02:46.535827Z",
     "shell.execute_reply.started": "2022-07-02T12:02:45.830695Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T12:00:01.068831Z",
     "iopub.status.busy": "2022-07-02T12:00:01.067552Z",
     "iopub.status.idle": "2022-07-02T12:02:25.153879Z",
     "shell.execute_reply": "2022-07-02T12:02:25.152906Z",
     "shell.execute_reply.started": "2022-07-02T12:00:01.068783Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.load_state_dict(torch.load(os.path.join(save_folder, \"best-auc.torch\")))\n",
    "scores_test = evaluation(trainer)\n",
    "filenames = [stem(x.path) for x in sounds_test]\n",
    "save_file_csv = os.path.join(save_folder, \"submission.csv\")\n",
    "pd.DataFrame({\"filename\": filenames, \"score\": scores_test}).to_csv(save_file_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Next?\n",
    "1. you can try to use different features (mfcc, fbanks, spectrogramm) with different parameters\n",
    "2. Use neural network which works with raw singal ([rawnet](https://github.com/Jungjee/RawNet), [sincnet](https://arxiv.org/abs/1808.00158), etc.)\n",
    "3. Use Image Processing models (efficientnet, resnet, squeezenet, mobilenet, etc.) be carefull by default that model used features dimension == 3, but spectral featrues dim == 1\n",
    "4. Use Real Noise instead of syntetic, just reimplement \"NoiseAugment\" to use different real life noises instead of torch.rand. You may use Musan dataset ([link kaggle](https://www.kaggle.com/datasets/nhattruongdev/musan-noise), [link openslr](https://www.openslr.org/17/)) for this\n",
    "5. Add pitch for specaug\n",
    "6. Use K-fold technique\n",
    "7. Voice Activiti Detection make a sense\n",
    "8. Fusion or stacking\n",
    "\n",
    "GL;HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample-00000.wav</td>\n",
       "      <td>0.019133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample-00001.wav</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename     score\n",
       "0  sample-00000.wav  0.019133\n",
       "1  sample-00001.wav  1.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sub = pd.read_csv(\"sub_3.csv\")\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_4.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        num = line[1:].split(\",\")[0]\n",
    "        res.append(float(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"score_1\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "      <th>score_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>sample-09995.wav</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.446993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>sample-09996.wav</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>0.999928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>sample-09997.wav</td>\n",
       "      <td>0.979637</td>\n",
       "      <td>0.997185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>sample-09998.wav</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.026393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>sample-09999.wav</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.108917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename     score   score_1\n",
       "9995  sample-09995.wav  0.997359  0.446993\n",
       "9996  sample-09996.wav  0.998248  0.999928\n",
       "9997  sample-09997.wav  0.979637  0.997185\n",
       "9998  sample-09998.wav  0.000015  0.026393\n",
       "9999  sample-09999.wav  0.000381  0.108917"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   filename  10000 non-null  object \n",
      " 1   score     10000 non-null  float64\n",
      " 2   score_1   10000 non-null  float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = (sub[\"score\"] + sub[\"score_1\"]) / 2\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"score\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.drop(columns = [\"score_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>sample-09995.wav</td>\n",
       "      <td>0.722176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>sample-09996.wav</td>\n",
       "      <td>0.999088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>sample-09997.wav</td>\n",
       "      <td>0.988411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>sample-09998.wav</td>\n",
       "      <td>0.013204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>sample-09999.wav</td>\n",
       "      <td>0.054649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename     score\n",
       "9995  sample-09995.wav  0.722176\n",
       "9996  sample-09996.wav  0.999088\n",
       "9997  sample-09997.wav  0.988411\n",
       "9998  sample-09998.wav  0.013204\n",
       "9999  sample-09999.wav  0.054649"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
